{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdecdd6e-8dd0-4583-a001-8c06ba7f4413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 7.44MB/s]         \n",
      "2024-06-13 17:56:57 INFO: Downloaded file to /home/marina/stanza_resources/resources.json\n",
      "2024-06-13 17:56:57 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-06-13 17:56:59 INFO: File exists: /home/marina/stanza_resources/en/default.zip\n",
      "2024-06-13 17:57:04 INFO: Finished downloading models and saved to /home/marina/stanza_resources\n",
      "2024-06-13 17:57:04 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 12.1MB/s]         \n",
      "2024-06-13 17:57:05 INFO: Downloaded file to /home/marina/stanza_resources/resources.json\n",
      "2024-06-13 17:57:05 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-06-13 17:57:05 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-06-13 17:57:05 INFO: Using device: cpu\n",
      "2024-06-13 17:57:05 INFO: Loading: tokenize\n",
      "2024-06-13 17:57:06 INFO: Loading: mwt\n",
      "2024-06-13 17:57:06 INFO: Loading: ner\n",
      "2024-06-13 17:57:06 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "### all together ########################\n",
    "import stanza\n",
    "import spacy\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import stanza.pipeline\n",
    "stanza.download('en')\n",
    "nlp_stanza = stanza.Pipeline('en', processors='tokenize,ner') \n",
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "\n",
    "path_journalists = './Biographies/Biographies_Journalists/*.txt'\n",
    "files_journalists = glob.glob(path_journalists)\n",
    "files_journalists = files_journalists[:3]\n",
    "\n",
    "path_sculptors = './Biographies/Biographies_Sculptors/*.txt'\n",
    "files_sculptors = glob.glob(path_sculptors)\n",
    "files_sculpors = files_sculptors[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "674547a9-623b-414f-a9fd-074c277caf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>ents_stanza</th>\n",
       "      <th>ents_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AquileoJ.Echeverría_Journalists.txt</td>\n",
       "      <td>[(Aquileo J. Echeverría, PERSON), (May 22, 186...</td>\n",
       "      <td>[(Aquileo J. Echeverría, PERSON), (May 22, 186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ThomasHenryShadwellClerke_Journalists.txt</td>\n",
       "      <td>[(Thomas Henry Shadwell Clerke, PERSON), (KH, ...</td>\n",
       "      <td>[(Thomas Henry Shadwell Clerke, PERSON), (KH, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Journalist_Journalists.txt</td>\n",
       "      <td>[(Matthew C. Nisbet, PERSON), (Walter Lippmann...</td>\n",
       "      <td>[(Matthew C. Nisbet, PERSON), (Walter Lippmann...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file_name  \\\n",
       "0        AquileoJ.Echeverría_Journalists.txt   \n",
       "1  ThomasHenryShadwellClerke_Journalists.txt   \n",
       "2                 Journalist_Journalists.txt   \n",
       "\n",
       "                                         ents_stanza  \\\n",
       "0  [(Aquileo J. Echeverría, PERSON), (May 22, 186...   \n",
       "1  [(Thomas Henry Shadwell Clerke, PERSON), (KH, ...   \n",
       "2  [(Matthew C. Nisbet, PERSON), (Walter Lippmann...   \n",
       "\n",
       "                                          ents_spacy  \n",
       "0  [(Aquileo J. Echeverría, PERSON), (May 22, 186...  \n",
       "1  [(Thomas Henry Shadwell Clerke, PERSON), (KH, ...  \n",
       "2  [(Matthew C. Nisbet, PERSON), (Walter Lippmann...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_ents_stanza(file):\n",
    "    with open(file, 'r') as f:\n",
    "        content = f.read()\n",
    "        doc = nlp_stanza(content)\n",
    "        ents = [(ent.text, ent.type) for ent in doc.ents]\n",
    "    return ents\n",
    "\n",
    "def extract_ents_spacy(file):\n",
    "    with open(file, 'r') as f:\n",
    "        content = f.read()\n",
    "        doc = nlp_spacy(content)\n",
    "        ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return ents\n",
    "\n",
    "def store_ents(files):\n",
    "    data = []\n",
    "    for file in files:\n",
    "        file_name = file.split('/')[-1]\n",
    "        data.append({'file_name': file_name, \n",
    "                     'ents_stanza': extract_ents_stanza(file), \n",
    "                     'ents_spacy': extract_ents_spacy(file)})\n",
    "    return data\n",
    "\n",
    "data_journalists = store_ents(files_journalists)\n",
    "df_journalists = pd.DataFrame(data_journalists)\n",
    "df_journalists.head()\n",
    "\n",
    "data_sculptors = store_ents(files_journalists)\n",
    "df_sculptors = pd.DataFrame(data_sculptors)\n",
    "df_sculptors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd9ce367-63c9-4dd6-94e3-feac9fcb4941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>package</th>\n",
       "      <th>avg_nb_ents</th>\n",
       "      <th>min_nb_ents</th>\n",
       "      <th>max_nb_ents</th>\n",
       "      <th>avg_nb_words</th>\n",
       "      <th>min_nb_words</th>\n",
       "      <th>max_nb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Journalists</td>\n",
       "      <td>stanza</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>46</td>\n",
       "      <td>235</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journalists</td>\n",
       "      <td>spacy</td>\n",
       "      <td>115.333333</td>\n",
       "      <td>47</td>\n",
       "      <td>242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sculptors</td>\n",
       "      <td>stanza</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>46</td>\n",
       "      <td>235</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sculptors</td>\n",
       "      <td>spacy</td>\n",
       "      <td>115.333333</td>\n",
       "      <td>47</td>\n",
       "      <td>242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category package  avg_nb_ents  min_nb_ents  max_nb_ents  avg_nb_words  \\\n",
       "0  Journalists  stanza   113.333333           46          235           2.0   \n",
       "1  Journalists   spacy   115.333333           47          242           2.0   \n",
       "2    Sculptors  stanza   113.333333           46          235           2.0   \n",
       "3    Sculptors   spacy   115.333333           47          242           2.0   \n",
       "\n",
       "   min_nb_words  max_nb_words  \n",
       "0             2             2  \n",
       "1             2             2  \n",
       "2             2             2  \n",
       "3             2             2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nb_ents_journalists_stanza = [len(ents) for ents in df_journalists['ents_stanza']]\n",
    "nb_ents_journalists_spacy = [len(ents) for ents in df_journalists['ents_spacy']]\n",
    "nb_ents_sculptors_stanza = [len(ents) for ents in df_sculptors['ents_stanza']]\n",
    "nb_ents_sculptors_spacy = [len(ents) for ents in df_sculptors['ents_spacy']]\n",
    "\n",
    "nb_ents_list = [nb_ents_journalists_stanza,nb_ents_journalists_spacy,nb_ents_sculptors_stanza,nb_ents_sculptors_spacy]\n",
    "\n",
    "avg_nb_ents = [np.mean(list) for list in nb_ents_list]\n",
    "min_nb_ents = [np.min(list) for list in nb_ents_list]\n",
    "max_nb_ents = [np.max(list) for list in nb_ents_list]\n",
    "\n",
    "\n",
    "nb_words_journalists_spacy = [len(ent[0]) for ent in [ents for ents in df_journalists['ents_stanza']]]\n",
    "nb_words_journalists_spacy = [len(ent[0]) for ent in [ents for ents in df_journalists['ents_spacy']]]\n",
    "nb_words_sculptors_stanza = [len(ent[0]) for ent in [ents for ents in df_sculptors['ents_stanza']]]\n",
    "nb_words_sculptors_spacy = [len(ent[0]) for ent in [ents for ents in df_sculptors['ents_spacy']]]\n",
    "\n",
    "nb_words_list = [nb_words_journalists_spacy,nb_words_journalists_spacy,nb_words_sculptors_stanza,nb_words_sculptors_spacy]\n",
    "\n",
    "avg_nb_words = [np.mean(list) for list in nb_words_list]\n",
    "min_nb_words = [np.min(list) for list in nb_words_list]\n",
    "max_nb_words = [np.max(list) for list in nb_words_list]\n",
    "\n",
    "data = {\"category\" : [\"Journalists\",\"Journalists\",\"Sculptors\",\"Sculptors\"],\n",
    "                \"package\" : [\"stanza\",\"spacy\",\"stanza\",\"spacy\"],\n",
    "                \"avg_nb_ents\" : avg_nb_ents,\n",
    "                \"min_nb_ents\" : min_nb_ents,\n",
    "                \"max_nb_ents\" : max_nb_ents,\n",
    "                \"avg_nb_words\" : avg_nb_words,\n",
    "                \"min_nb_words\" : min_nb_words,\n",
    "                \"max_nb_words\" : max_nb_words}\n",
    "                \n",
    "\n",
    "df_statistics = pd.DataFrame(data)\n",
    "df_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203f1fb-46a8-41f4-833b-ed3eae5df0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
